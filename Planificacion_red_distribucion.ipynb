{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRJuiWxBT8tP"
      },
      "source": [
        "# Colombia dataset\n",
        "\n",
        "  * Author: Esteban Cid y Jesús Cid\n",
        "  * Version 0.0: Jan, 2024."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PI0gYbLdT8tU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import matplotlib.cm as cm\n",
        "from sklearn.metrics import silhouette_samples, silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "\n",
        "try:\n",
        "    from pyclustering.cluster.kmedians import kmedians\n",
        "    from cartopy.io import shapereader\n",
        "    from ortools.constraint_solver import pywrapcp\n",
        "    from ortools.constraint_solver import routing_enums_pb2\n",
        "except:\n",
        "    !pip install pyclustering\n",
        "    !pip install cartopy\n",
        "    !pip install ortools\n",
        "    from pyclustering.cluster.kmedians import kmedians\n",
        "    from cartopy.io import shapereader\n",
        "    from ortools.constraint_solver import pywrapcp\n",
        "    from ortools.constraint_solver import routing_enums_pb2\n",
        "\n",
        "import geopandas\n",
        "from shapely.geometry import mapping\n",
        "\n",
        "from geopy.distance import geodesic\n",
        "\n",
        "from time import time\n",
        "import os\n",
        "import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxiMVALWzY_n"
      },
      "outputs": [],
      "source": [
        "# Para leer el fichero de datos directamente de google drive\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount(\"/content/drive\")\n",
        "    os.chdir(\"/content/drive/My Drive/TFM_Esteban\")\n",
        "    in_colab = True\n",
        "except:\n",
        "    in_colab = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgjMdX9DtLN-"
      },
      "outputs": [],
      "source": [
        "# ######################################\n",
        "# Parámetros de configuracion de usuario\n",
        "# ######################################\n",
        "\n",
        "# Numero de centros de distribución.\n",
        "# Poner aqui un valor de prueba. El valor definitivo debe elegirse después de\n",
        "# la primera ejecución, en función de los resultados de las metricas de cluster\n",
        "# (silouhette, davis-boulding, etc)\n",
        "num_centros = 7\n",
        "\n",
        "# Parámetros del CVRP ---------------------------------------------------------\n",
        "\n",
        "# Nivel de demanda\n",
        "demanda_media = 2\n",
        "\n",
        "# Capacidad de cada vehiculo (mejor no modificarlo)\n",
        "vc = 3_500\n",
        "\n",
        "# Periodo de demanda (escribir 'all' para usar el acumulado de todos los meses)\n",
        "mes = '202207'\n",
        "\n",
        "# Tiempo máximo de optimización, por cada cluster.\n",
        "# Limita el tiempo de búsqueda de rutas al optimizador.\n",
        "# Tiempos largos garantizan mejores soluciones. Tiempos cortos proporcionan\n",
        "# soluciones subóptimas. Si es demasiado corto, el optimizador puede no\n",
        "# encontrar ninguna solución\n",
        "tmax = 500\n",
        "\n",
        "# Cluster utilizado para hacer la prueba de planificacion de rutas con un solo\n",
        "# centro de distribución\n",
        "cluster_de_prueba = 5\n",
        "\n",
        "# ###################\n",
        "# Parámetros técnicos\n",
        "# ###################\n",
        "\n",
        "# Máx. nº de tiendas\n",
        "# Poner valor pequeño para pruebas, y grande para usar el dataset completo\n",
        "nmax = 999999999999\n",
        "\n",
        "# Número de ciudades para el tsp. Poner un valor menor que el total de ciudades\n",
        "# para hacer pruebas que no duren demasiado\n",
        "# (este parámetro no se usa en la planificación de rutas mediante CVRP)\n",
        "n_loc_tsp = 800\n",
        "\n",
        "# Métrica de distancia\n",
        "# A elegir entre \"euclidea\" (rápida pero imprecisa), \"haversine\" (algo más\n",
        "# lenta pero bastante más precisa) o \"geodesic\" (muy precisa pero muy lenta)\n",
        "distance_metric = \"haversine\"\n",
        "\n",
        "# Escala para conversión a distancias enteras en ortools.\n",
        "scale_D = 1e9\n",
        "# Escala para conversión a demandas enteras en ortools.\n",
        "scale_M = 1e6\n",
        "\n",
        "# #######################\n",
        "# Parámetros de ejecución\n",
        "# #######################\n",
        "\n",
        "# Estos parámetros sirven para filtrar secciones de código que no se deseen\n",
        "# ejecutar\n",
        "compute_silouhette = False\n",
        "compute_distances = False\n",
        "compute_kmedians = False\n",
        "compute_tsp = False\n",
        "compute_ckdb = False\n",
        "remove_zero_demand_cities = True\n",
        "compute_pruebavrp = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO3DiUAcT8tW"
      },
      "source": [
        "## 1. Carga de datos.\n",
        "\n",
        "The dataset contains coordinate of populations from Colombia. Coordinates are given by latitude and longitude. You should evaluate geodesic distances to evaluate the costs.\n",
        "\n",
        "### 1.1. Lectura del fichero de datos\n",
        "\n",
        "En primer lugar, cargamos los datos del fichero en una tabla (dataframe). Podemos previsualizar el contenido de las primeras entradas de la tabla."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFhWohn67qi3"
      },
      "source": [
        "A continuación"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WvKLxRBhT8tX"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "df_cities = pd.read_excel('Base_anonima_curada2.xlsx')\n",
        "df_cities.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NW6SY47R77bR"
      },
      "source": [
        "Los atributos de cada entrada son:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MXGFkl1Cw8KY"
      },
      "outputs": [],
      "source": [
        "print(df_cities.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nS71bKV72g8"
      },
      "source": [
        "### 1.2. Extracción de coordenadas geograficas y pesos.\n",
        "\n",
        "El atributo 'latitud longitud' contiene las coordenadas geográficas en formato texto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TugJ-ywUw8Kc"
      },
      "outputs": [],
      "source": [
        "if mes == 'all':\n",
        "   mes = 'Acumuladas (Calculado por mí)'\n",
        "\n",
        "# Extrae datos de la columna 'latitud longitud'\n",
        "geodata_str = df_cities['latitud longitud'].tolist()\n",
        "# Extrae datos de demanda monetaria acumulada\n",
        "demanda_str = df_cities['Acumuladas (Calculado por mi)'].tolist()\n",
        "demandames_str = df_cities[mes].tolist()\n",
        "\n",
        "# Hay que eliminar las entradas sin coordenadas\n",
        "# (esto es necesario en el dataset original, pero quizás ya no hace falta con\n",
        "# el dataset curado)\n",
        "\n",
        "# Suprime entradas vacías\n",
        "geodata_str, demanda_str, demandames_str = zip(\n",
        "    *[(g, w, z) for g, w, z in zip(geodata_str, demanda_str, demandames_str) if g != 0])\n",
        "geodata_str = list(geodata_str)\n",
        "demanda_str = list(demanda_str)\n",
        "demandames_str = list(demandames_str)\n",
        "\n",
        "# Separa latitud de longitud\n",
        "geodata_str = [x.split(',') for x in geodata_str]\n",
        "\n",
        "# Corrige errores de formato en los datos, y convierte latitud y longitud a\n",
        "# números en coma flotante\n",
        "geodata_x = []\n",
        "demanda_x = []\n",
        "demandames_x=[]\n",
        "for x, w, z in zip(geodata_str, demanda_str, demandames_str):\n",
        "    if len(x) < 2:\n",
        "        print(f'No hay comas: {x}')\n",
        "    elif '------------' in x[1]:\n",
        "        print(f'Lineas continuas: {x}')\n",
        "    elif 's ' in x[0]:\n",
        "        print(f'Entrada eliminada: {x}')\n",
        "    elif x[1][-1] in {'.', 'v'}:\n",
        "        print(f'Entrada eliminada: {x}')\n",
        "    else:\n",
        "        # Note that we take coordinates in reverse order\n",
        "        geodata_x.append([float(x[1]), float(x[0])])\n",
        "        demanda_x.append(w)\n",
        "        demandames_x.append(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhuTat_2AV9i"
      },
      "source": [
        "Algunas entradas tienen localizaciones incorrectas, fuera del mapa de Colombia, y deben suprimirse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEcYtZtBw8Ke"
      },
      "outputs": [],
      "source": [
        "# Filtrado por coordenadas\n",
        "geodata_x2 = []\n",
        "demanda_x2 = []\n",
        "demandames_x2 = []\n",
        "for x, w, z in zip(geodata_x, demanda_x, demandames_x):\n",
        "    # Filtrado por longitud\n",
        "    if x[1] < -10 or x[1] > 11.99:\n",
        "        print(f'Entrada eliminada: {x}')\n",
        "    # Filtrado por latitud\n",
        "    elif x[0] < -80 or x[0] > -69.99:\n",
        "        print(f'Entrada eliminada: {x}')\n",
        "    else:\n",
        "        geodata_x2.append([x[0], x[1]])\n",
        "        demanda_x2.append(w)\n",
        "        demandames_x2.append(z)\n",
        "\n",
        "# Demanda, en unidades monetarias.\n",
        "demanda_x2 = np.array(demanda_x2)\n",
        "demandames_x2 = np.array(demandames_x2)\n",
        "# Perfil de demanda normalizado (suma 1)\n",
        "d_profile = demandames_x2 / np.sum(demandames_x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fix82IA4BXlr"
      },
      "source": [
        "Los datos ya están preparados, y pueden cargarse en una matrix, ${\\bf X}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uy_jvdnbw8Kg"
      },
      "outputs": [],
      "source": [
        "# Load GPS coordinates in a numpy array\n",
        "X = np.array(geodata_x2)\n",
        "n_cities = X.shape[0]\n",
        "\n",
        "print(\"-- Bounding box\")\n",
        "print(f\"-- -- Longitud: Mínima: {np.min(X[:, 0])}, máxima: {np.max(X[:, 0])}\")\n",
        "print(f\"-- -- Latitud: Mínima: {np.min(X[:, 1])}, máxima: {np.max(X[:, 1])}\")\n",
        "print(f'Dataset cargado con {n_cities} ciudades')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqALGttZDJQA"
      },
      "source": [
        "Tranformaremos la matriz de datos para que las unidades sean aproximadamente kilométricas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDig-PxmDBdR"
      },
      "outputs": [],
      "source": [
        "def flat_factors(verbose=False):\n",
        "    \"\"\"\n",
        "    De termina los factores de escalado que deben aplicarse a las coordenadas\n",
        "    geodesicas para aproximar el resultado por un plano\n",
        "    \"\"\"\n",
        "\n",
        "    # Definimos en primer lugar un espacio delimitado por dos paralelos y dos\n",
        "    # meridianos sobre la superficie terrestre, que aproximaremos por un\n",
        "    # rectángulo en el plano.\n",
        "    lat_min, lat_max = 0.16073, 11.71425\n",
        "    long_min, long_max = -78.7934, -70.74338\n",
        "\n",
        "    # Estos son los vertices del espacio definido por los meridianos y paralelos\n",
        "    box = np.array([[lat_min, long_min],\n",
        "                    [lat_min, long_max],\n",
        "                    [lat_max, long_min],\n",
        "                    [lat_max, long_max]])\n",
        "\n",
        "    # Para trasformar las coordenadas geográficas en kilométricas, calculamos\n",
        "    # primero las distancias geodésicas entre estos vértices, en kilómetros\n",
        "    distWE_por_el_N_total = geodesic(box[0], box[1]).kilometers\n",
        "    distWE_por_el_S_total = geodesic(box[2], box[3]).kilometers\n",
        "    dist_NS1_total = geodesic(box[0], box[2]).kilometers\n",
        "    dist_NS2_total = geodesic(box[1], box[3]).kilometers\n",
        "\n",
        "    # Distancias W-E en unidaddes de \"incrementos de longitud\"\n",
        "    distWE_por_el_N = distWE_por_el_N_total / (long_max - long_min)\n",
        "    distWE_por_el_S = distWE_por_el_S_total / (long_max - long_min)\n",
        "    # Distancias N-S en unidaddes de \"incrementos de latitud\"\n",
        "    dist_NS1 = dist_NS1_total / (lat_max - lat_min)\n",
        "    dist_NS2 = dist_NS2_total / (lat_max - lat_min)\n",
        "\n",
        "    if verbose:\n",
        "        print(\"Distancias totales:\")\n",
        "        print(distWE_por_el_N_total)\n",
        "        print(distWE_por_el_S_total)\n",
        "        print(dist_NS1_total)\n",
        "        print(dist_NS2_total)\n",
        "\n",
        "        print(\"Distancias por unidad de coordenada geográfica:\")\n",
        "        print(distWE_por_el_N)\n",
        "        print(distWE_por_el_S)\n",
        "        print(dist_NS1)\n",
        "        print(dist_NS2)\n",
        "\n",
        "    # Factores que habrá que aplicar a los incrementos N-S y W-E para convertirlos\n",
        "    # en distancias kilometricas aproximadas\n",
        "    factor_NS = dist_NS1;\n",
        "    factor_WE = (distWE_por_el_N + distWE_por_el_S) / 2;\n",
        "\n",
        "    return factor_NS, factor_WE\n",
        "\n",
        "def flat_projection(X, verbose=False):\n",
        "    \"\"\"\n",
        "    Proyecta las coordenadas geodesicas en X, de forma aproximada, sobre un\n",
        "    plano\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy array\n",
        "        Matriz de coordenadas geodesicas\n",
        "    \"\"\"\n",
        "\n",
        "    factor_NS, factor_WE = flat_factors(verbose=verbose)\n",
        "\n",
        "    # Matriz Z, del mismo tamaño que X, pero con ceros\n",
        "    Z = np.zeros(X.shape);\n",
        "\n",
        "    # Rellena con las coordenadas proyectadas\n",
        "    Z[:, 1] = factor_NS * X[:, 1]\n",
        "    Z[:, 0] = factor_WE * X[:, 0]\n",
        "\n",
        "    return Z\n",
        "\n",
        "def inverse_flat_projection(Z):\n",
        "    \"\"\"\n",
        "    Recupera las coordenadas geodesicas a partir de las coordenadas proyectadas\n",
        "    en Z\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy array\n",
        "        Matriz de coordenadas geodesicas\n",
        "    \"\"\"\n",
        "\n",
        "    factor_NS, factor_WE = flat_factors(verbose=False)\n",
        "\n",
        "    # Matriz Z, del mismo tamaño que X, pero con ceros\n",
        "    X = np.zeros(Z.shape);\n",
        "\n",
        "    # Rellena con las coordenadas proyectadas\n",
        "    X[:, 1] = Z[:, 1] / factor_NS\n",
        "    X[:, 0] = Z[:, 0] / factor_WE\n",
        "\n",
        "    return X\n",
        "\n",
        "Z = flat_projection(X, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k30bMOPbDCyL"
      },
      "source": [
        "## 2. Visualización de datos.\n",
        "\n",
        "A continuación cargaremos las coordenadas geográficas del contorno de colombia, para visualizar los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5nLjPinw8Kh"
      },
      "outputs": [],
      "source": [
        "# Lee datos de las fronteras de Colombia\n",
        "shpfilename = shapereader.natural_earth('50m', 'cultural', 'admin_0_countries')\n",
        "dfC = geopandas.read_file(shpfilename)\n",
        "Cdata = dfC.loc[dfC['SOVEREIGNT']=='Colombia', 'geometry'].values[0]\n",
        "\n",
        "# Extrae los puntos que definen la fromtera de Colombia, definidos sobre el\n",
        "# rectangulo que hemos definido como espacio de trabajo\n",
        "C = mapping(Cdata)['coordinates']\n",
        "cx, cy = zip(*C[0][0])\n",
        "# Frontera en coordenadas geodesicas\n",
        "Cx = np.array([cx, cy]).T\n",
        "# Frontera en coordenadas proyectadas\n",
        "Cz = flat_projection(Cx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afyXuqzpDOm1"
      },
      "source": [
        "Y ahora visualizamos los datos sobre el mapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn2GlDVnT8tX"
      },
      "outputs": [],
      "source": [
        "def plot_map(Z, Cz, centroids=None, labels=None, show_plot=False, make_figure=True):\n",
        "    \"\"\"\n",
        "    Dibuja un mapa de Colombia y las ciudades, y opcionalmente los centroides\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Z : numpy array\n",
        "        Array con las coordenadas de las ciudades.\n",
        "    Cz : numpy array\n",
        "        Array con las coordenadas proyectadas de la frontera de Colombia.\n",
        "    centroids : numpy array, optional\n",
        "        Array con las coordenadas de los centroides.\n",
        "        El valor por defecto es None (en cuyo caso no se dibujan centroides).\n",
        "    show_plot : bool, optional\n",
        "        Indica si se debe mostrar el gráfico. El valor por defecto es False.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create figure\n",
        "    if make_figure:\n",
        "        fig = plt.figure(figsize=(8, 8))\n",
        "    # Plot Colombia\n",
        "    plt.plot(Cz[:, 0], Cz[:, 1], c='gray')\n",
        "    # Plot cities.\n",
        "    plt.scatter(Z[:, 0], Z[:, 1], c=labels, marker='.', s=0.1)   # , s=ms)   #, c='cyan')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if centroids is not None:\n",
        "        plt.scatter(centroids[:, 0], centroids[:, 1], c= \"red\", marker='x',\n",
        "                    label=\"Centroids\")\n",
        "\n",
        "    plt.axis('equal')\n",
        "    plt.axis('off')\n",
        "\n",
        "    if show_plot:\n",
        "        plt.show()\n",
        "\n",
        "    return\n",
        "\n",
        "# Plot Colombia and locations\n",
        "plot_map(Z, Cz, centroids=None, show_plot=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx1b20_68XM1"
      },
      "source": [
        "## 3. Algoritmos de agrupamiento (clustering)\n",
        "\n",
        "### 3.1 K-means\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8xEgLVI7OIi"
      },
      "source": [
        "K-means mostrando coordenadas de clusters y nº clientes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9S-j0iV7Nug"
      },
      "outputs": [],
      "source": [
        "# KMeans algorithm\n",
        "kmeans = KMeans(n_clusters=num_centros, n_init='auto', random_state=0)\n",
        "kmeans.fit(Z, sample_weight=demanda_x2)\n",
        "\n",
        "# Obtiene el cluster asociado a cada muestra\n",
        "labels = kmeans.labels_\n",
        "\n",
        "# Obtiene los centroides\n",
        "centroids = kmeans.cluster_centers_\n",
        "\n",
        "# Obtiene el número total de puntos en cada cluster\n",
        "num_points_in_cluster = np.bincount(labels)\n",
        "\n",
        "# Score\n",
        "score = kmeans.inertia_\n",
        "\n",
        "# Dimensiona la figura\n",
        "plot_map(Z, Cz, centroids=centroids, labels=labels, show_plot=False)\n",
        "# Muestra el número total de puntos en cada cluster\n",
        "for i in range(num_centros):\n",
        "    plt.annotate(f'Centro [{i}]', (centroids[i, 0] + 30, centroids[i, 1]))\n",
        "\n",
        "plt.title(\"KMeans Clustering\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MeVBjNiGnly"
      },
      "source": [
        "Estas son las coordenadas geográficas de los centroides:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-Yo1qt57XeH"
      },
      "outputs": [],
      "source": [
        "print(\"-- Coordenadas geográficas de los centroides:\")\n",
        "centroids_x = inverse_flat_projection(centroids)\n",
        "lat_centroids = centroids_x[:, 0]\n",
        "lon_centroids = centroids_x[:, 1]\n",
        "\n",
        "for i in range(len(lat_centroids)):\n",
        "    print(f'[{i}]: {lat_centroids[i]:.8f}, {lon_centroids[i]:.8f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPjtDXLQSZqQ"
      },
      "outputs": [],
      "source": [
        "# Rango de valores de n_clusters que deseas probar (de 2 a 30)\n",
        "range_n_clusters = range(2, 31)\n",
        "\n",
        "# Inicializa una lista para almacenar las puntuaciones de inercia\n",
        "inertia_scores = []\n",
        "\n",
        "# Bucle para calcular la inercia para cada valor de n_clusters\n",
        "for n_clusters in range_n_clusters:\n",
        "    # Inicializa el agrupador KMeans con n_clusters y una semilla aleatoria\n",
        "    kmeans = KMeans(n_clusters=n_clusters, n_init='auto', random_state=0)\n",
        "    kmeans.fit(Z, sample_weight=demanda_x2)\n",
        "\n",
        "    # Obtiene la inercia y la almacena en la lista\n",
        "    inertia_scores.append(kmeans.inertia_)\n",
        "\n",
        "    # Imprime la puntuación de inercia para cada n_clusters en una línea\n",
        "    print(f\"Para n_clusters={n_clusters}, la puntuación de inercia es: {kmeans.inertia_}\")\n",
        "\n",
        "# Visualización de las puntuaciones de inercia en dos gráficos. A la izquierda, en escala lineal, y a la derecha, en escala logarítmica\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(range_n_clusters, inertia_scores, marker='o')\n",
        "plt.title('Inercia vs número de clusters')\n",
        "plt.xlabel('Número de clusters (n_clusters)')\n",
        "plt.ylabel('Puntuación de Inercia')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range_n_clusters, inertia_scores, marker='o')\n",
        "plt.yscale('log')\n",
        "plt.title('Inercia vs número de clusters')\n",
        "plt.xlabel('Número de clusters (n_clusters)')\n",
        "plt.ylabel('Puntuación de Inercia (log)')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUyZ9CNoGnl0"
      },
      "source": [
        "Para determinar el número de clusters, exploraremos diferentes opciones"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ci87DvZ8pI9"
      },
      "source": [
        "### 3.1.2 K-medias con silhouette"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIy2YEbR8y0h"
      },
      "outputs": [],
      "source": [
        "if compute_silouhette:\n",
        "\n",
        "    # Supongamos que Z es tu matriz resultante\n",
        "\n",
        "    # Rango de valores de n_clusters que deseas probar\n",
        "    range_n_clusters = [2, 3, 4, 5, 6, 7, 8, 9]\n",
        "\n",
        "    # Inicializa cluster scores\n",
        "    ch_score = []\n",
        "    db_score = []\n",
        "\n",
        "    # Creamos una figura para visualizar los resultados\n",
        "    plt.figure(figsize=(8, 4))\n",
        "\n",
        "    for n_clusters in range_n_clusters:\n",
        "\n",
        "        # ###### Clustering #######################################################\n",
        "        print(f\"-- Aplicando k-means con {n_clusters} centroides      \\r\", end=\"\")\n",
        "\n",
        "        # Inicializa el agrupador KMeans con n_clusters y una semilla aleatoria\n",
        "        clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=10)\n",
        "\n",
        "        # Hacemos el fit sin usar los sample_weights, porque las metricas de\n",
        "        # cluster no los utilizan\n",
        "        cluster_labels = clusterer.fit_predict(Z)\n",
        "\n",
        "        # Calcula el score de silueta promedio para todos los datos\n",
        "        silhouette_avg = silhouette_score(Z, cluster_labels)\n",
        "\n",
        "        ch_score.append(calinski_harabasz_score(Z, cluster_labels))\n",
        "        db_score.append(davies_bouldin_score(Z, cluster_labels))\n",
        "\n",
        "        # Calcula y visualiza los scores de silueta para cada muestra\n",
        "        sample_silhouette_values = silhouette_samples(Z, cluster_labels)\n",
        "\n",
        "        # ###### Visualización ####################################################\n",
        "\n",
        "        # Inicializa una figura con 1 fila y 2 columnas\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
        "        # fig.set_size_inches(18, 7)\n",
        "        fig.set_size_inches(12, 4)\n",
        "\n",
        "        # El 1er subplot es el plot de silueta\n",
        "        ax1.set_xlim([-0.1, 1])\n",
        "        # Inserta espacio en blanco entre plots de silueta individuales para demarcar claramente los clusters\n",
        "        ax1.set_ylim([0, len(Z) + (n_clusters + 1) * 10])\n",
        "\n",
        "        y_lower = 10\n",
        "        for i in range(n_clusters):\n",
        "            # Agrega scores de silueta para muestras pertenecientes al cluster i y ordénalos\n",
        "            ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
        "            ith_cluster_silhouette_values.sort()\n",
        "\n",
        "            size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
        "            y_upper = y_lower + size_cluster_i\n",
        "\n",
        "            color = cm.nipy_spectral(float(i) / n_clusters)\n",
        "            ax1.fill_betweenx(\n",
        "                np.arange(y_lower, y_upper), 0, ith_cluster_silhouette_values,\n",
        "                facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "            # Etiqueta los plots de silueta con números de cluster en el medio\n",
        "            ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
        "\n",
        "            # Calcula el nuevo y_lower para el próximo plot\n",
        "            y_lower = y_upper + 10  # 10 for the 0 samples\n",
        "\n",
        "        ax1.set_title(f\"Silhouette plot for {n_clusters} clusters\")\n",
        "        ax1.set_xlabel(\"Silhouette coefficient values\")\n",
        "        ax1.set_ylabel(\"Cluster label\")\n",
        "\n",
        "        # Línea vertical para el score de silueta promedio de todos los valores\n",
        "        ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "        ax1.set_yticks([])  # Limpia las etiquetas del eje y\n",
        "        ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "        # 2do plot que muestra los clusters formados\n",
        "        colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
        "        ax2.scatter(Z[:, 0], Z[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors,\n",
        "                    edgecolor=\"k\")\n",
        "\n",
        "        # Etiqueta los clusters\n",
        "        centers = clusterer.cluster_centers_\n",
        "        ax2.scatter(centers[:, 0], centers[:, 1], marker=\"o\", c=\"white\", alpha=1,\n",
        "                    s=200, edgecolor=\"k\")\n",
        "\n",
        "        for i, c in enumerate(centers):\n",
        "            ax2.scatter(c[0], c[1], marker=f\"${i}$\", alpha=1, s=50, edgecolor=\"k\")\n",
        "\n",
        "        ax2.set_title(f\"Visualization of {n_clusters} clusters\")\n",
        "        ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
        "        ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
        "\n",
        "        plt.suptitle(f\"Silhouette analysis for KMeans clustering with {n_clusters} clusters\",\n",
        "                    fontsize=14, fontweight=\"bold\")\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zu82mCOAzFfI"
      },
      "outputs": [],
      "source": [
        "if compute_silouhette:\n",
        "    # Rango de valores de n_clusters que deseas probar (de 2 a 50)\n",
        "    range_n_clusters = range(2, 51)\n",
        "\n",
        "    # Inicializa listas para almacenar puntuaciones de silueta\n",
        "    silhouette_avg_list = []\n",
        "    silhouette_values_list = []\n",
        "\n",
        "    for n_clusters in range_n_clusters:\n",
        "        print(f\"-- Num clusters = {n_clusters}      \\r\", end=\"\")\n",
        "\n",
        "        # Inicializa el agrupador KMeans con n_clusters y una semilla aleatoria\n",
        "        clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=10)\n",
        "        # Hacemo el fit sin sample weights porque las metricas de cluster posteriores\n",
        "        # no los utilizan\n",
        "        cluster_labels = clusterer.fit_predict(Z)\n",
        "\n",
        "        # Calcula el coeficiente de silueta promedio para todos los datos\n",
        "        silhouette_avg = silhouette_score(Z, cluster_labels)\n",
        "        silhouette_avg_list.append(silhouette_avg)\n",
        "\n",
        "        # Calcula y almacena los valores de silueta para cada muestra\n",
        "        silhouette_values = silhouette_samples(Z, cluster_labels)\n",
        "        silhouette_values_list.append(silhouette_values)\n",
        "\n",
        "    # Imprime el valor máximo del coeficiente de silueta y su correspondiente n_clusters\n",
        "    max_silhouette_avg_index = np.argmax(silhouette_avg_list)\n",
        "    print(f\"The maximum silhouette score is {silhouette_avg_list[max_silhouette_avg_index]} for n_clusters = {range_n_clusters[max_silhouette_avg_index]}\")\n",
        "\n",
        "    # Visualización de las puntuaciones de silueta en un gráfico\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.plot(range_n_clusters, silhouette_avg_list, '.-')\n",
        "    plt.ylabel(\"Silhouette score (higher is better)\")\n",
        "    plt.xlabel(\"Number of clusters\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqnjNb4zzH7G"
      },
      "source": [
        "#### 4.1.3 K-means con Calinski y Davies Bouldin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd12ydt_l4L5"
      },
      "outputs": [],
      "source": [
        "if compute_ckdb:\n",
        "    # Rango de valores de n_clusters que deseas probar\n",
        "    range_n_clusters = range(2, 102, 1)\n",
        "\n",
        "    # Inicializa cluster scores\n",
        "    ch_score = []\n",
        "    db_score = []\n",
        "\n",
        "    for n_clusters in range_n_clusters:\n",
        "        print(f\"-- Num clusters = {n_clusters}      \\r\", end=\"\")\n",
        "\n",
        "        # ###### Clustering #######################################################\n",
        "\n",
        "        # Inicializa el agrupador KMeans con n_clusters y una semilla aleatoria\n",
        "        clusterer = KMeans(n_clusters=n_clusters, n_init=\"auto\", random_state=10)\n",
        "        cluster_labels = clusterer.fit_predict(Z)\n",
        "\n",
        "        ch_score.append(calinski_harabasz_score(Z, cluster_labels))\n",
        "        db_score.append(davies_bouldin_score(Z, cluster_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXHVLYIanfgZ"
      },
      "outputs": [],
      "source": [
        "if compute_ckdb:\n",
        "    print(f\"The Calinskk-Harabasz score is maximum for n_clusters = {range_n_clusters[np.argmax(ch_score)]}\")\n",
        "    print(f\"The Davies-Bouldin score is maximum for n_clusters = {range_n_clusters[np.argmin(db_score)]}\")\n",
        "\n",
        "    plt.figure(figsize=(15, 4))\n",
        "    plt.subplot(121)\n",
        "    plt.plot(range_n_clusters, ch_score, '.-')\n",
        "    plt.ylabel(\"Calinski-Harabasz score (higher is better)\")\n",
        "    plt.xlabel(\"Number of clusters\")\n",
        "\n",
        "    plt.subplot(122)\n",
        "    plt.plot(range_n_clusters, db_score, '.-')\n",
        "    plt.ylabel(\"Davies-Bouldin score (lower is better)\")\n",
        "    plt.xlabel(\"Number of clusters\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYQRTz5BT8tZ"
      },
      "source": [
        "### 3.2 K-medians"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhF18xEPT8tZ"
      },
      "outputs": [],
      "source": [
        "if compute_kmedians:\n",
        "    # KMedians algorithm\n",
        "    K = num_centros\n",
        "\n",
        "    # Selecciona centroides iniciales de forma aleatoria entre los datos\n",
        "    initial_cluster_centers = Z[np.random.permutation(X.shape[0])[:K],:];\n",
        "\n",
        "    # Aplica k-medians\n",
        "    kmedians_instance = kmedians(Z, initial_cluster_centers)\n",
        "    kmedians_instance.process();\n",
        "\n",
        "    # Extrae clusters\n",
        "    clusters = kmedians_instance.get_clusters()\n",
        "    y_kmedians = np.zeros([X.shape[0]])\n",
        "    y_kmedians[clusters[0]] = 0\n",
        "    y_kmedians[clusters[1]] = 1\n",
        "    C = np.array(kmedians_instance.get_medians())\n",
        "    print(C)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5MJ38TwcVMZ"
      },
      "outputs": [],
      "source": [
        "if compute_kmedians:\n",
        "    # Plotting\n",
        "    plot_map(Z, cx, cy, centroids=C, show_plot=False)\n",
        "    plt.title(\"KMedians Clustering\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    # crosstab(y, y_kmedians)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZPIDPoGT8tY"
      },
      "source": [
        "## 4. Matriz de Distancias\n",
        "\n",
        "En general, es conveniente precalcular la matriz de distancias entre todas las ciudades antes de lanzar el cálculo de rutas.\n",
        "\n",
        "Dicha matriz debería contener las distancias geodésicas. Sin embargo, esto consume mucho tiempo. Por este motivo, definimos tres funciones que realizan el cálculo con diferentes niveles de precisión y velocidad:\n",
        "\n",
        "* **geodesic_distance**: es el más preciso (supone que la tierra es un elipsoide de revolución) pero es muy lento.\n",
        "* **haversine_distance**: simplifica el cálculo suponiendo tierra exactamente esférica, y por tanto es algo más impreciso, pero bastante más rápido (~1min)\n",
        "* **euclidean_distance**: hace una aproximacion de tierra plana, muy rápida pero bastante imprecisa, sobre todo en el cálculo de distancias paralelas al ecuador.\n",
        "\n",
        "Es importante notar que `euclidean_distance` necesita como entrada la proyección de los datos sobre el plano calculada en la matriz ${\\bf Z}$. El resto de funciones necesitan datos como latitud y longitud."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7SZC3xW7T8tZ"
      },
      "outputs": [],
      "source": [
        "# Initialize distance matrix\n",
        "def geodesic_distance(X):\n",
        "    \"\"\"\n",
        "    Calcula la matriz de distancias geodésicas entre las ciudades.\n",
        "    Este método es el más exacto, pero es muy lento, y no se recomienda su uso\n",
        "    para matrices de entrada con más de 100 ciudades.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy array\n",
        "        Array con las coordenadas de las ciudades.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    D : numpy array\n",
        "        Matriz de distancias geodésicas entre las ciudades.\n",
        "    \"\"\"\n",
        "\n",
        "    # Initialize distance matrix\n",
        "    n_cities = X.shape[0]\n",
        "    D = np.zeros((n_cities, n_cities))\n",
        "\n",
        "    # Compute distance matrix\n",
        "    for i in range(n_cities):\n",
        "        print(f\"-- City {i+1} out of {n_cities} \\r\", end=\"\")\n",
        "        for j in range(n_cities):\n",
        "            if j > i:\n",
        "                D[i][j] = geodesic(X[i], X[j]).kilometers\n",
        "            else:\n",
        "                D[i][j] = D[j][i]\n",
        "    return D\n",
        "\n",
        "\n",
        "def haversine_distance(X):\n",
        "    \"\"\"\n",
        "    Calcula la matriz de distancias haversinas entre las ciudades.\n",
        "    Este método es más rápido que el método geodésico, pero es menos exacto,\n",
        "    porque supone que la Tierra es una esfera perfecta en lugar de un elipsoide.\n",
        "    \"\"\"\n",
        "\n",
        "    # Radio de la Tierra en kilómetros\n",
        "    R = 6371.0\n",
        "\n",
        "    # Convertir de grados a radianes\n",
        "    X_rad = np.radians(X)\n",
        "\n",
        "    # Extraer latitudes y longitudes\n",
        "    lat = np.array([X_rad[:, 0]]).T\n",
        "    lon = np.array([X_rad[:, 1]]).T\n",
        "\n",
        "    # Calcular las diferencias de latitudes y longitudes\n",
        "    print(\"-- Calculando diferencias de latitudes y longitudes...\")\n",
        "    delta_lat = lat.T - lat\n",
        "    delta_lon = lon.T - lon\n",
        "\n",
        "    # Aplicar la fórmula del semiverseno\n",
        "    print(\"-- Aplicando la fórmula del semiverseno...\")\n",
        "    cos_lat = np.cos(lat)\n",
        "    a = (np.sin(delta_lat / 2.0)**2\n",
        "         + cos_lat * cos_lat.T * np.sin(delta_lon / 2.0)**2)\n",
        "    D = 2 * R * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
        "\n",
        "    return D\n",
        "\n",
        "def euclidean_distance(X):\n",
        "    \"\"\"\n",
        "    Computes the euclidean distance matrix between cities. It is very fast, but\n",
        "    also very inaccurate, because it assumes a flat Earth...\n",
        "    \"\"\"\n",
        "\n",
        "    Z = flat_projection(X)\n",
        "\n",
        "    S = Z @ Z.T\n",
        "    modZ = np.array([np.diag(S)])\n",
        "    D = np.sqrt(modZ + modZ.T - 2 * S)\n",
        "\n",
        "    return D\n",
        "\n",
        "def calcula_distancias(X, metric):\n",
        "    \"\"\"\n",
        "    Calcula la matriz de distancias entre las ciudades, utilizando la métrica\n",
        "    especificada.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : numpy array\n",
        "        Array con las coordenadas de las ciudades.\n",
        "    metric : string\n",
        "        Métrica de distancia a utilizar. Puede ser \"euclidea\", \"haversine\" o\n",
        "        \"geodesic\".\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    D : numpy array\n",
        "        Matriz de distancias entre las ciudades.\n",
        "    \"\"\"\n",
        "\n",
        "    if metric == \"euclidea\":\n",
        "        D = euclidean_distance(X)\n",
        "    elif metric == \"haversine\":\n",
        "        D = haversine_distance(X)\n",
        "    elif metric == \"geodesic\":\n",
        "        D = geodesic_distance(X)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown distance metric: {metric}\")\n",
        "\n",
        "    return D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bcmygi-z9ic5"
      },
      "source": [
        "## 5. Planificación de rutas\n",
        "\n",
        "### 5.1 Ruta simple\n",
        "\n",
        "A modo de ensayo, para generar la ruta más corta que recorre todos los nodos y retorna al punto de partida. Este es un problema clásico en optimización combinatoria, denominado el _problema del viajante_ o TSP (Traveling Salesman Problem).\n",
        "\n",
        "Para calcular la rota óptima utilizaremos la librería `ortools`.\n",
        "\n",
        "Dado que el cálculo del camino más corto es computacionalmente costoso, permitimos el uso de un subconjunto de localizaciones.\n",
        "\n",
        "Extraemos la submatriz con `n_loc_tsp` entradas, y añadimos una localización final de coordenadas nulas (que no tiene sentido como localización real, pero es un artificio útil para que el algoritmo de enrutamiento calcule una ruta de retorno).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GnI2KBJ9nSF"
      },
      "outputs": [],
      "source": [
        "# Parámetros del algoritmo\n",
        "num_routes = 1   # Solo una ruta (TSP clásico)\n",
        "\n",
        "# Extrae submatriz de datos\n",
        "Xsub = X[:n_loc_tsp, :]\n",
        "# Añadimos punto virtual en el (0,0), que se fija como punto de partida\n",
        "Xe = np.vstack((Xsub, np.array([[0, 0]])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFE3w07mI9Vo"
      },
      "source": [
        "A continuación calculamos la matriz de distancias entre todas las localizaciones.\n",
        "\n",
        "IMPORTANTE: la librería `ortools` requiere distancias enteras. Por este motivo, es necesario escalar la matriz de distancias por un factor entero grande, para garantizar cierta precisión. Un factor $1e6$ puede ser suficiente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVz3Pk6bH8tF"
      },
      "outputs": [],
      "source": [
        "# Calcula la matriz de distancias\n",
        "D = calcula_distancias(Xe, distance_metric)\n",
        "\n",
        "print(f\"-- Maximum distance = {np.max(D)}\")\n",
        "print(f\"-- Minimum distance = {np.min(D + 1e100*(D==0))}\")\n",
        "print(f\"-- Distance matrix computed with dimension {D.shape}\")\n",
        "\n",
        "# Escalamos la matriz de distancias para convertirla en una matriz de enteros,\n",
        "# que es el formato que necesita ortools\n",
        "D = (scale_D * D).astype(int)\n",
        "D[:, -1] = 10\n",
        "D[-1, :] = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbbsxxQmJ-tp"
      },
      "source": [
        "Para aplicar `ortools` es necesario definir dos funciones: una, que proporcione valores de la matriz de distancias, y otra que devuelva la solución obtenida para el TSP. Adicionalmente, definimos una función para calcular la longitud total de una ruta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWgyziN1933n"
      },
      "outputs": [],
      "source": [
        "def distance_callback(from_ind, to_index):\n",
        "    \"\"\" Returns the distance between the two nodes. \"\"\"\n",
        "    # Convert from routing variable Index to distance matrix NodeIndex.\n",
        "    from_node = manager.IndexToNode(from_ind)\n",
        "    to_node = manager.IndexToNode(to_index)\n",
        "\n",
        "    return D[from_node][to_node]\n",
        "\n",
        "def get_tsp_solution(manager, routing, solution):\n",
        "    \"\"\"\n",
        "    Returns TSP solution.\n",
        "    \"\"\"\n",
        "\n",
        "    index = routing.Start(0)\n",
        "    route = [manager.IndexToNode(index)]\n",
        "\n",
        "    while not routing.IsEnd(index):\n",
        "        previous_index = index\n",
        "        index = solution.Value(routing.NextVar(index))\n",
        "        route.append(manager.IndexToNode(index))\n",
        "\n",
        "    return route\n",
        "\n",
        "def tsp_score(D, route):\n",
        "    \"\"\"\n",
        "    Computes the total score for the input route given by distance matrix D\n",
        "    It assumes that the routes return to the starting location from the last\n",
        "    city in the list\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    D : np.ndarray\n",
        "        Distance matrix\n",
        "    route : list of int\n",
        "        List of indices of the route\n",
        "    \"\"\"\n",
        "\n",
        "    # List of destination for all cities in route\n",
        "    dest = route.copy()\n",
        "    dest.append(dest.pop(0))\n",
        "\n",
        "    return sum([D[o][d] for o, d in zip(route, dest)])\n",
        "\n",
        "def plot_path(best_path, Z, Zsub, Cz):\n",
        "    \"\"\"\n",
        "    Plots a route in the map using locations in X\n",
        "    \"\"\"\n",
        "\n",
        "    plot_map(Z, Cz, show_plot=False)\n",
        "    plt.plot(Zsub[best_path, 0], Zsub[best_path, 1], '-', c='green', linewidth=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaKekMBNGnmE"
      },
      "source": [
        "Definimos los objetos que necesita el solver para funcionar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AyJLFDg6ZB7"
      },
      "outputs": [],
      "source": [
        "if compute_tsp:\n",
        "    start = time()\n",
        "    base_point = len(D) - 1   # len(D)\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(n_loc_tsp + 1, num_routes, base_point)\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    # search_parameters.first_solution_strategy = (\n",
        "    #     routing_enums_pb2.FirstSolutionStrategy.PATH_CHEAPEST_ARC)\n",
        "\n",
        "    # Sugerencias de GPT para reducir la carga computacional\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.SAVINGS)\n",
        "    # Cambiar PATH_CHEAPEST_ARC por alguno de estos:\n",
        "    # SAVINGS, CHRISTOFIDES, ALL_UNPERFORMED\n",
        "\n",
        "    # search_parameters.local_search_metaheuristic = (\n",
        "    #     routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n",
        "\n",
        "    # search_parameters.time_limit.seconds = 30  # Limita a 30 segundos, por ejemplo\n",
        "\n",
        "    print(f\"{time()-start:.4f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXn3gtwrGnmG"
      },
      "source": [
        "Lanzamos el solver para encontrar la ruta:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWWOlijuzlrI"
      },
      "outputs": [],
      "source": [
        "if compute_tsp:\n",
        "\n",
        "    start = time()\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "    print(f\"{time()-start:.4f} segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPINNavdGnmH"
      },
      "source": [
        " FInalmente, capturamos la mejor ruta y la mostramos sobre el mapa."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHmem-kwzlYX"
      },
      "outputs": [],
      "source": [
        "if compute_tsp:\n",
        "\n",
        "    start = time()\n",
        "\n",
        "    if solution:\n",
        "        best_path = get_tsp_solution(manager, routing, solution)\n",
        "\n",
        "    # Captura la secuencia de localizaciones recorrida por la ruta obtenica.\n",
        "    best_path = [x for x in best_path[1:-1]]\n",
        "\n",
        "    score_best_path = tsp_score(D / scale_D, best_path)\n",
        "\n",
        "    print(f\"-- Score = {score_best_path}\")\n",
        "    print(f\"{time()-start:.4f} segundos\")\n",
        "\n",
        "    Z = flat_projection(X)\n",
        "    Zsub = flat_projection(Xsub)\n",
        "    plot_path(best_path, Z, Zsub, Cz)\n",
        "    plt.plot(Zsub[best_path, 0], Zsub[best_path, 1], '-', c='green', linewidth=0.5)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEsMnLVUNhoy"
      },
      "source": [
        "### 5.2. Vehicle Routing Problem (VRP)\n",
        "\n",
        "Variables importantes:\n",
        "\n",
        "* Z: coordenadas kilométricas de todas las tiendas.\n",
        "* D: distancias entre todas las tiendas\n",
        "* labels: lista del cluster asociado a cada tienda (labels[i] es el clustes de la tienda de coordenadas Z[i].\n",
        "* centroids: Cordenadas de los centroides.\n",
        "* num_points_in_cluster: tamaño de cada cluster.\n",
        "* weights_x2: la demanda de cada tienda\n",
        "\n",
        "Hacer todo el proceso para un solo cluster, por ejemplo, el i. Por ejemplo:\n",
        "\n",
        "i = 3\n",
        "...\n",
        "\n",
        "Ahora nos interesa:\n",
        "\n",
        "* El cluster i, tiene cooordenadas centroids[i].\n",
        "* Las tiendas del centroide i: Z[k] es una tienda del cluster i si label[k]=i.\n",
        "\n",
        "Proceso:\n",
        "  1. Seleccionar de la matriz Z la submatriz Zi que contiene solamente las filas de Z que se corresponden con las posiciones en las que labels toma el valor i. Es decir, Z[k] estará en Zi si label[k]=i.\n",
        "\n",
        "  2. Hacer lo mismo con weights_x2.\n",
        "\n",
        "  3. Apilar las tiendas con su centroide: es decir, hacer la matriz extendida Zei que apile centroids[i] y Zi. Zei[0] será el centroide y debajo estarán todas las tiendas.\n",
        "\n",
        "  4. Calcular la matriz Di de distancias entre todas las filas de la matriz extendida, Zei.\n",
        "\n",
        "  5. Crear el data_model del CVRP:\n",
        "````\n",
        "data[\"distance_matrix\"] = Di\n",
        "data[\"demands\"] = Los datos de las demandas de las tiendas correspondientes.\n",
        "data[\"num_vehicles\"] = el valor que quieras.\n",
        "data[\"depot] = 0.  <-- la posición del centroide en la matriz Ze.\n",
        "````\n",
        "\n",
        "  6.  Ejecutar el código del CVRP.\n",
        "\n",
        "  7. Si todo funciona para el cluster i, meter todo el código en un bucle.\n",
        "````\n",
        "    for i in range(7):\n",
        "        # Todo el codigo aquí...\n",
        "````        \n",
        "\n",
        "Definimos, en primer lugar, un conjunto de funciones que nos permitan  procesar los datos con secuencias de comandos sencillas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nXzq7wYXT8tZ"
      },
      "outputs": [],
      "source": [
        "\"\"\"Capacited Vehicles Routing Problem (CVRP).\"\"\"\n",
        "def create_data_model(Di, demands, vc=1_000):\n",
        "    \"\"\"Stores the data for the problem.\"\"\"\n",
        "    data = {}\n",
        "    data[\"distance_matrix\"] = Di\n",
        "    data[\"demands\"] = demands\n",
        "    # El número de vehículos tiene que soportar la demanda total\n",
        "    data[\"num_vehicles\"] = int((sum(demands) - 1) / vc) + 1\n",
        "    print(f\"-- Se necesitan {data['num_vehicles']} vehiculos\")\n",
        "\n",
        "    # Todos los vehiculos tienen la misma capacidad\n",
        "    data[\"vehicle_capacities\"] = [vc] * data[\"num_vehicles\"]\n",
        "\n",
        "    data[\"depot\"] = 0\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pN-EYsFGM2Mk"
      },
      "outputs": [],
      "source": [
        "def solve_cvrp(Di, demands, vc, tmax=100):\n",
        "    \"\"\"\n",
        "    Solve the CVRP problem. This is the algorithmic core of this notebook.\n",
        "    It solves the route planning problem for a single cluster.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    Di : np.ndarray\n",
        "        Distance matrix\n",
        "    demands : array-like\n",
        "        Demand of every location\n",
        "    vc : int\n",
        "        Capacity of every single vehicle.\n",
        "    tmax : int, optional (default=100)\n",
        "        Time limit for the computation of the routs from a single center\n",
        "    \"\"\"\n",
        "\n",
        "    # Get distance\n",
        "    def distance_callback(from_index, to_index):\n",
        "        \"\"\"Returns the distance between the two nodes.\"\"\"\n",
        "        # Convert from routing variable Index to distance matrix NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        to_node = manager.IndexToNode(to_index)\n",
        "        return data[\"distance_matrix\"][from_node][to_node]\n",
        "\n",
        "    # Get demand.\n",
        "    def demand_callback(from_index):\n",
        "        \"\"\"Returns the demand of the node.\"\"\"\n",
        "        # Convert from routing variable Index to demands NodeIndex.\n",
        "        from_node = manager.IndexToNode(from_index)\n",
        "        return data[\"demands\"][from_node]\n",
        "\n",
        "    # Instantiate the data problem.\n",
        "    data = create_data_model(Di, demands, vc=vc)\n",
        "\n",
        "    # Create the routing index manager.\n",
        "    manager = pywrapcp.RoutingIndexManager(\n",
        "        len(data[\"distance_matrix\"]), data[\"num_vehicles\"], data[\"depot\"])\n",
        "\n",
        "    # Create Routing Model.\n",
        "    routing = pywrapcp.RoutingModel(manager)\n",
        "\n",
        "    # Register method to get distances\n",
        "    transit_callback_index = routing.RegisterTransitCallback(distance_callback)\n",
        "\n",
        "    # Define cost of each arc.\n",
        "    routing.SetArcCostEvaluatorOfAllVehicles(transit_callback_index)\n",
        "\n",
        "    # Register method to get demands\n",
        "    demand_callback_index = routing.RegisterUnaryTransitCallback(demand_callback)\n",
        "\n",
        "    # Add capacity constraints\n",
        "    routing.AddDimensionWithVehicleCapacity(\n",
        "        demand_callback_index,\n",
        "        0,  # null capacity slack\n",
        "        data[\"vehicle_capacities\"],  # vehicle maximum capacities\n",
        "        True,  # start cumul to zero\n",
        "        \"Capacity\")\n",
        "\n",
        "    # Setting first solution heuristic.\n",
        "    search_parameters = pywrapcp.DefaultRoutingSearchParameters()\n",
        "    search_parameters.first_solution_strategy = (\n",
        "        routing_enums_pb2.FirstSolutionStrategy.CHRISTOFIDES)\n",
        "\n",
        "    search_parameters.local_search_metaheuristic = (\n",
        "        routing_enums_pb2.LocalSearchMetaheuristic.GUIDED_LOCAL_SEARCH)\n",
        "\n",
        "    search_parameters.time_limit.FromSeconds(tmax)\n",
        "\n",
        "    # Solve the problem.\n",
        "    print(\"-- -- -- Running solver. This may take some time...\")\n",
        "    t0 = time()\n",
        "    solution = routing.SolveWithParameters(search_parameters)\n",
        "    print(f\"-- -- CVRP solved in {time()-t0} secs.\")\n",
        "\n",
        "    return data, manager, routing, solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcOp06IwtWV7"
      },
      "outputs": [],
      "source": [
        "def print_solution(data, manager, routing, solution, scale=1e9):\n",
        "    \"\"\"Prints solution on console.\n",
        "    \"\"\"\n",
        "\n",
        "    if not solution:\n",
        "      print(\"-- No se ha encontrado ninguna solución\")\n",
        "      return\n",
        "\n",
        "    print(f\"-- Total distance: {solution.ObjectiveValue() / scale} km\")\n",
        "    total_distance = 0\n",
        "    total_load = 0\n",
        "\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        print(f\"-- -- Vehicle {vehicle_id}.\")\n",
        "        index = routing.Start(vehicle_id)\n",
        "\n",
        "        plan_output = f\"-- -- Route for vehicle {vehicle_id}:\\n\"\n",
        "        route_distance = 0\n",
        "        route_load = 0\n",
        "        nodes = []\n",
        "        while not routing.IsEnd(index):\n",
        "            node_index = manager.IndexToNode(index)\n",
        "            nodes.append(node_index)\n",
        "\n",
        "            try:\n",
        "                route_load += data[\"demands\"][node_index]\n",
        "            except:\n",
        "                print(f\"-- -- Fallo en nodo {node_index}\")\n",
        "            plan_output += f\" {node_index} Load({route_load}) ->\"\n",
        "            previous_index = index\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "            route_distance += routing.GetArcCostForVehicle(\n",
        "                previous_index, index, vehicle_id)\n",
        "\n",
        "        plan_output += f\" {manager.IndexToNode(index)} Load({route_load})\\n\"\n",
        "        plan_output += f\"-- -- Distance of the route: {route_distance /scale } km\\n\"\n",
        "        plan_output += f\"-- -- Load of the route: {route_load}\\n\"\n",
        "        print(plan_output)\n",
        "        total_distance += route_distance\n",
        "        total_load += route_load\n",
        "\n",
        "    print(f\"-- Total distance of all routes: {total_distance/scale:.3f} km\")\n",
        "    print(f\"-- Total load of all routes: {total_load}\")\n",
        "\n",
        "    return\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7gQyxZ5WelP"
      },
      "source": [
        "#### 5.2.1. Análisis de una ruta simple\n",
        "\n",
        "A continuacion analizamos una ruta individual\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9Ax8i4xWYxi"
      },
      "outputs": [],
      "source": [
        "def get_best_path(data, manager, routing, solution):\n",
        "    \"\"\"\n",
        "    Extrae el conjunto de mejores rutas encontradas, una por cada vehiculo.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    solution :\n",
        "        Variable solución devuelta por el algoritmo de optimización\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "        best_path : list of list\n",
        "            Es una lista de listas. Cada lista es la secuencia de ciudades que\n",
        "            debe recorrer un vehiculo\n",
        "    \"\"\"\n",
        "\n",
        "    best_path = []\n",
        "    path_size = []\n",
        "\n",
        "    # Si no hay solución devuelve una lista vacia\n",
        "    if not solution:\n",
        "        return best_path, path_size\n",
        "\n",
        "    # Obtener el mejor camino de la solución\n",
        "    for vehicle_id in range(data[\"num_vehicles\"]):\n",
        "        index = routing.Start(vehicle_id)\n",
        "        best_path_i = []\n",
        "        path_size_i = 0\n",
        "        while not routing.IsEnd(index):\n",
        "            node_index = manager.IndexToNode(index)\n",
        "            best_path_i.append(node_index)\n",
        "            previous_index = index\n",
        "            index = solution.Value(routing.NextVar(index))\n",
        "            path_size_i += routing.GetArcCostForVehicle(\n",
        "                previous_index, index, vehicle_id)\n",
        "\n",
        "        best_path.append(best_path_i)\n",
        "        path_size.append(path_size_i)\n",
        "\n",
        "    return best_path, path_size\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYESlQioQAZL"
      },
      "outputs": [],
      "source": [
        "# Extraer submatriz Zi y apilar las tiendas con su centroide\n",
        "# Supongamos que i es el índice del cluster que te interesa (en este caso, i=1)\n",
        "i = cluster_de_prueba\n",
        "\n",
        "# ###### Selecciona coordenadas y pesos del cluster i\n",
        "# Filtrar las filas de Z correspondientes al cluster i\n",
        "Xi = X[labels == i]\n",
        "\n",
        "# Filtrar las demandas correspondientes al cluster i\n",
        "demanda_total = demanda_media * n_cities\n",
        "demanda_i = demanda_total * d_profile[labels == i]\n",
        "\n",
        "# Elimina localizaciones sin demanda:\n",
        "print(f\"-- Dataset con {len(demanda_i)} localizaciones\")\n",
        "if remove_zero_demand_cities:\n",
        "  n_zero = sum(demanda_i==0)\n",
        "  if n_zero > 0:\n",
        "      print(f\"-- Hay {n_zero} localizaciones sin demanda\")\n",
        "      # Suprime todas las localizaciones con peso 0.\n",
        "      Xi = Xi[demanda_i > 0]\n",
        "      demanda_i = demanda_i[demanda_i > 0]\n",
        "      print(f\"-- Dataset reducido a {len(demanda_i)} localizaciones\")\n",
        "\n",
        "# Recorta dataset a un tamaño máximo (sólo  para depuración de código)\n",
        "Xi = Xi[:nmax]\n",
        "demanda_i = demanda_i[:nmax]\n",
        "\n",
        "# Apilar el centroide y las tiendas\n",
        "Xei = np.vstack([centroids_x[i], Xi])\n",
        "demanda_i = np.hstack([[0], demanda_i])\n",
        "\n",
        "# Calcula matriz de distancias\n",
        "Di = calcula_distancias(Xei, distance_metric)\n",
        "\n",
        "# Escala parametros a valores enteros.\n",
        "# Esto es necesario porque ortools solamente admite valores enteros\n",
        "demanda_i = (scale_M * demanda_i).astype(int)\n",
        "vc_scaled = int(scale_M * vc)\n",
        "Di = (scale_D * Di).astype(int)\n",
        "\n",
        "plt.semilogy(sorted(demanda_i))\n",
        "plt.xlabel(\"Cliente (ordenado por demanda)\")\n",
        "plt.ylabel(\"Demanda\")\n",
        "print(f\"-- Demanda mínima: {min(demanda_i[1:])}\")\n",
        "print(f\"-- Demanda mediana: {np.median(demanda_i[1:])}\")\n",
        "print(f\"-- Demanda media: {np.mean(demanda_i[1:])}\")\n",
        "print(f\"-- Demanda máxima: {max(demanda_i)}\")\n",
        "print(f\"-- Demanda total: {sum(demanda_i)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHjbQC6tP8-P"
      },
      "source": [
        "Lanzamos el planificador de rutas:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YbgH8Em0qxUP"
      },
      "outputs": [],
      "source": [
        "if compute_pruebavrp:\n",
        "\n",
        "    print(f\"-- Planificación de rutas para el cluster {i}\")\n",
        "    data, manager, routing, solution = solve_cvrp(Di, demanda_i, vc_scaled, tmax=tmax)\n",
        "\n",
        "    # Print solution on console.\n",
        "    print_solution(data, manager, routing, solution)\n",
        "    best_path, path_size = get_best_path(data, manager, routing, solution)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXShnRQkq1pM"
      },
      "outputs": [],
      "source": [
        "def plot_multipaths(best_path, Z, Zsub, Cz, centroids):\n",
        "    \"\"\"\n",
        "    Plots a route in the map using locations in X\n",
        "    \"\"\"\n",
        "\n",
        "    plot_map(Z, Cz, centroids=centroids, show_plot=False)\n",
        "\n",
        "    if isinstance(best_path[0], list):\n",
        "        for path_i in best_path:\n",
        "           plt.plot(Zsub[path_i, 0], Zsub[path_i, 1], '-', linewidth=0.5)\n",
        "    else:\n",
        "        plt.plot(Zsub[best_path, 0], Zsub[best_path, 1], '-', c='green', linewidth=0.5)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Print solution on console.\n",
        "if compute_pruebavrp and solution:\n",
        "\n",
        "    # Llamar a la función de visualización\n",
        "    Zei = flat_projection(Xei)\n",
        "    plot_multipaths(best_path, Z, Zei, Cz, centroids)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpEZTgl-nrwP"
      },
      "source": [
        "#### 5.2.2. Planificación completa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEBX95TWiNeQ"
      },
      "outputs": [],
      "source": [
        "# Plot Colombia, the cities and the centroids\n",
        "plot_map(Z, Cz, centroids=centroids, show_plot=False)\n",
        "\n",
        "# Inicializa variables del bucle\n",
        "distancia_total = 0\n",
        "route_plan = []\n",
        "route_plan_distances = []\n",
        "\n",
        "demanda_total = demanda_media * n_cities\n",
        "num_centros = centroids.shape[0]\n",
        "data = [0] * num_centros\n",
        "manager = [0] * num_centros\n",
        "routing = [0] * num_centros\n",
        "solution = [0] * num_centros\n",
        "\n",
        "for i in range(centroids.shape[0]):\n",
        "\n",
        "    print(f\"\\n----------------------------------------\")\n",
        "    print(f\"-- Planificando rutas para el cluster {i}\")\n",
        "\n",
        "    # ###### Selecciona coordenadas y pesos del cluster i\n",
        "    # Filtrar las filas de Z correspondientes al cluster i\n",
        "    Xi = X[labels == i]\n",
        "\n",
        "    # Filtrar las demandas correspondientes al cluster i\n",
        "    demanda_i = demanda_total * d_profile[labels == i]\n",
        "\n",
        "    # Elimina localizaciones sin demanda:\n",
        "    print(f\"-- -- Dataset con {len(demanda_i)} localizaciones\")\n",
        "    if remove_zero_demand_cities:\n",
        "      n_zero = sum(demanda_i==0)\n",
        "      if n_zero > 0:\n",
        "          print(f\"-- -- Hay {n_zero} localizaciones sin demanda\")\n",
        "          # Suprime todas las localizaciones con peso 0.\n",
        "          Xi = Xi[demanda_i > 0]\n",
        "          demanda_i = demanda_i[demanda_i > 0]\n",
        "          print(f\"-- -- Dataset reducido a {len(demanda_i)} localizaciones\")\n",
        "\n",
        "    # Recorta dataset a un tamaño máximo (sólo  para depuración de código)\n",
        "    Xi = Xi[:nmax]\n",
        "    demanda_i = demanda_i[:nmax]\n",
        "\n",
        "    # Apilar el centroide y las tiendas\n",
        "    Xei = np.vstack([centroids_x[i], Xi])\n",
        "    demanda_i = np.hstack([[0], demanda_i])\n",
        "\n",
        "    # Calcula matriz de distancias\n",
        "    Di = calcula_distancias(Xei, distance_metric)\n",
        "\n",
        "    # Escala parametros a valores enteros.\n",
        "    # Esto es necesario porque ortools solamente admite valores enteros\n",
        "    demanda_i = (scale_M * demanda_i).astype(int)\n",
        "    vc_scaled = int(scale_M * vc)\n",
        "    Di = (scale_D * Di).astype(int)\n",
        "\n",
        "    print(f\"-- -- Demanda mínima y máxima: {min(demanda_i[1:])} -- {max(demanda_i)}\")\n",
        "    print(f\"-- -- Demanda total: {sum(demanda_i)}\")\n",
        "\n",
        "    data[i], manager[i], routing[i], solution[i] = solve_cvrp(Di, demanda_i, vc_scaled, tmax=tmax)\n",
        "    print_solution(data[i], manager[i], routing[i], solution[i])\n",
        "\n",
        "    # Obtiene las rutas calculadas para el cluster i\n",
        "    best_path, path_size = get_best_path(data[i], manager[i], routing[i], solution[i])\n",
        "\n",
        "    # Incluye el nodo de salida, que es también de retorno, al final de la ruta\n",
        "    if isinstance(best_path[0], list):\n",
        "        for path_k in best_path:\n",
        "            path_k.append(path_k[0])\n",
        "    else:\n",
        "        best_path.append(best_path[0])\n",
        "\n",
        "    # Añade esas rutas a una lista con todas las rutas\n",
        "    route_plan.append(best_path)\n",
        "    route_plan_distances.append(path_size)\n",
        "\n",
        "    # Traza las rutas del cluster i\n",
        "    if len(best_path) > 0:\n",
        "        Zei = flat_projection(Xei)\n",
        "        if isinstance(best_path[0], list):\n",
        "            for path_k in best_path:\n",
        "                plt.plot(Zei[path_k, 0], Zei[path_k, 1], '-', linewidth=0.5)\n",
        "        else:\n",
        "            plt.plot(Zei[best_path, 0], Zei[best_path, 1], '-', c='green', linewidth=0.5)\n",
        "\n",
        "    # Distancia acumulada de todas las rutas y todos los clusters\n",
        "    distancia_total += solution[i].ObjectiveValue() / scale_D\n",
        "\n",
        "print(f\"-- DISTANCIA TOTAL: {distancia_total:.3f} km\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNzdLsbeFbD9"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2wShbNnyoqm"
      },
      "outputs": [],
      "source": [
        "# Plot Colombia, the cities and the centroids\n",
        "plt.figure(figsize=(16, 16))\n",
        "\n",
        "for i in range(centroids.shape[0]):\n",
        "\n",
        "    plt.subplot(4, 2, i+1)\n",
        "    plot_map(Z, Cz, centroids=centroids, show_plot=False, make_figure=False)\n",
        "\n",
        "    # ###### Selecciona coordenadas y pesos del cluster i\n",
        "    # Filtrar las filas de Z correspondientes al cluster i\n",
        "    Xi = X[labels == i]\n",
        "\n",
        "    # Filtrar las demandas correspondientes al cluster i\n",
        "    demanda_i = demanda_total * d_profile[labels == i]\n",
        "\n",
        "    # Elimina localizaciones sin demanda:\n",
        "    if remove_zero_demand_cities:\n",
        "        print(f\"-- -- Hay {sum(demanda_i==0)} localizaciones sin demanda\")\n",
        "        Xi = Xi[demanda_i > 0]\n",
        "\n",
        "    # Recorta dataset a un tamaño máximo (sólo para depuración de código)\n",
        "    Xi = Xi[:nmax]\n",
        "\n",
        "    # Apilar el centroide y las tiendas\n",
        "    Xei = np.vstack([centroids_x[i], Xi])\n",
        "\n",
        "    # Obtiene las rutas calculadas para el cluster i\n",
        "    best_path = route_plan[i]\n",
        "\n",
        "    # Traza las rutas del cluster i\n",
        "    xmin, xmax = 1e100, -1e100\n",
        "    ymin, ymax = 1e100, -1e100\n",
        "\n",
        "    if len(best_path) > 0:\n",
        "        Zei = flat_projection(Xei)\n",
        "        num_rutas = len(best_path)\n",
        "        for path_k in best_path:\n",
        "            plt.plot(Zei[path_k, 0], Zei[path_k, 1], '-', linewidth=0.5)\n",
        "            xmin = min(xmin, min(Zei[path_k, 0]))\n",
        "            xmax = max(xmax, max(Zei[path_k, 0]))\n",
        "            ymin = min(ymin, min(Zei[path_k, 1]))\n",
        "            ymax = max(ymax, max(Zei[path_k, 1]))\n",
        "\n",
        "    d = 50\n",
        "    xmin, xmax = xmin - d, xmax + d\n",
        "    ymin, ymax = ymin - d, ymax + d\n",
        "\n",
        "    plt.xlim([xmin, xmax])\n",
        "    plt.ylim([ymin, ymax])\n",
        "    plt.axis('on')\n",
        "    plt.title(f\"Centro {i}: {num_rutas} rutas\")\n",
        "\n",
        "print(f\"-- DISTANCIA TOTAL: {distancia_total:.3f} km\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP_upzW1XQr-"
      },
      "outputs": [],
      "source": [
        "print(route_plan)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_MeMNA6MkF4C"
      },
      "outputs": [],
      "source": [
        "all_routes = []\n",
        "for routes in route_plan_distances:\n",
        "    all_routes += routes\n",
        "\n",
        "media= distancia_total/len(all_routes)\n",
        "\n",
        "plt.figure(figsize=(4,8))\n",
        "plt.plot(np.array(all_routes) / scale_D)\n",
        "\n",
        "#Agregar linea horizontal en la media\n",
        "plt.axhline(y=media, color='r', linestyle='--')\n",
        "\n",
        "plt.show()\n",
        "print(f\"La media es: {media}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4zyUyTDkIBg"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}